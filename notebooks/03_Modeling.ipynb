{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbb9c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cleaned data rows: 2414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>bhk</th>\n",
       "      <th>price</th>\n",
       "      <th>sq_feet</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bhk_num</th>\n",
       "      <th>price_per_sqft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mapusa</td>\n",
       "      <td>Office Space</td>\n",
       "      <td>100000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>15.590853</td>\n",
       "      <td>73.810215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1298.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taleigao</td>\n",
       "      <td>2 BHK</td>\n",
       "      <td>10000000</td>\n",
       "      <td>11905.0</td>\n",
       "      <td>15.470266</td>\n",
       "      <td>73.822567</td>\n",
       "      <td>2.0</td>\n",
       "      <td>839.983200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location           bhk     price  sq_feet   latitude  longitude  bhk_num  \\\n",
       "0    Mapusa  Office Space    100000     77.0  15.590853  73.810215      0.0   \n",
       "1  Taleigao         2 BHK  10000000  11905.0  15.470266  73.822567      2.0   \n",
       "\n",
       "   price_per_sqft  \n",
       "0     1298.701299  \n",
       "1      839.983200  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: load cleaned data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "fp = Path(\"../data/processed/goa_cleaned.csv\")\n",
    "if not fp.exists():\n",
    "    raise FileNotFoundError(f\"Expected cleaned CSV at {fp}. If missing, run 01_preprocessing.ipynb first.\")\n",
    "df_clean = pd.read_csv(fp)\n",
    "print(\"Loaded cleaned data rows:\", len(df_clean))\n",
    "df_clean.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d3abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_model shape: (2414, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sq_feet</th>\n",
       "      <th>price_per_sqft</th>\n",
       "      <th>bhk_num</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1298.701299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.512935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000000</td>\n",
       "      <td>11905.0</td>\n",
       "      <td>839.983200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.118096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000000</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.118096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  sq_feet  price_per_sqft  bhk_num  log_price\n",
       "0    100000     77.0     1298.701299      0.0  11.512935\n",
       "1  10000000  11905.0      839.983200      2.0  16.118096\n",
       "2  10000000  12500.0      800.000000      2.0  16.118096"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: prepare df_model and target\n",
    "df_model = df_clean.copy()\n",
    "df_model['log_price'] = np.log1p(df_model['price'])\n",
    "print(\"df_model shape:\", df_model.shape)\n",
    "df_model[['price','sq_feet','price_per_sqft','bhk_num','log_price']].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c217de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 1931 Test rows: 483\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_model[['location','sq_feet','bhk_num','price_per_sqft']]\n",
    "y = df_model['log_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train rows:\", X_train.shape[0], \"Test rows:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6288844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor fitted. Output shape (sample): (1931, 160)\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: preprocessor (scikit-learn 1.4+ compatible)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numeric_features = ['sq_feet','bhk_num','price_per_sqft']\n",
    "categorical_features = ['location']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# quick fit-transform test on training data to ensure no hidden errors\n",
    "_ = preprocessor.fit_transform(X_train)\n",
    "print(\"Preprocessor fitted. Output shape (sample):\", _.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277f392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest trained. RMSE (log): 0.07213265442604154\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: train RandomForest pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "model_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RandomForest trained. RMSE (log):\", float(rmse_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf1149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved to ../models/rf_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: save the pipeline\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "dump(model_rf, \"../models/rf_pipeline.pkl\")\n",
    "print(\"✓ Model saved to ../models/rf_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55616839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pipeline. Sample preds (log): [17.12393513 16.07410643 15.82634765]\n",
      "Sample preds (INR): [27342015, 9569642, 7469566]\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: load and test\n",
    "from joblib import load\n",
    "pipe = load(\"../models/rf_pipeline.pkl\")\n",
    "# test predict on a sample from X_test\n",
    "sample = X_test.iloc[:3].copy()\n",
    "preds = pipe.predict(sample)\n",
    "print(\"Loaded pipeline. Sample preds (log):\", preds)\n",
    "print(\"Sample preds (INR):\", [int(round(np.expm1(p))) for p in preds])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066d7ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote src/models/predict_helper.py\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: write helper script (src/models/predict_helper.py)\n",
    "helper_code = r'''\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(__file__).parents[2] / \"models\" / \"rf_pipeline.pkl\"\n",
    "\n",
    "def load_model():\n",
    "    return joblib.load(MODEL_PATH)\n",
    "\n",
    "def predict_price(model, location, sq_feet, bhk_num, price_per_sqft=None, default_pps=None):\n",
    "    # If caller doesn't supply price_per_sqft, use default or model fallback\n",
    "    X = pd.DataFrame([{\n",
    "        \"location\": location,\n",
    "        \"sq_feet\": float(sq_feet),\n",
    "        \"bhk_num\": float(bhk_num),\n",
    "        \"price_per_sqft\": float(price_per_sqft) if price_per_sqft is not None else float(default_pps)\n",
    "    }])\n",
    "    log_pred = model.predict(X)[0]\n",
    "    return {\"pred_log\": float(log_pred), \"pred_price_inr\": int(round(np.expm1(log_pred)))}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    m = load_model()\n",
    "    print(predict_price(m, \"Porvorim\", 1200, 2, price_per_sqft=2000))\n",
    "'''\n",
    "Path(\"../src/models\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../src/models/predict_helper.py\").write_text(helper_code)\n",
    "print(\"Wrote src/models/predict_helper.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2d6f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_log': 15.051782873565772, 'pred_price_inr': 3442755}\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: test helper\n",
    "import importlib.util, sys\n",
    "spec = importlib.util.spec_from_file_location(\"ph\", \"../src/models/predict_helper.py\")\n",
    "ph = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(ph)\n",
    "\n",
    "model_loaded = ph.load_model()\n",
    "print(ph.predict_price(model_loaded, \"Porvorim\", 1200, 2, price_per_sqft=2000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c2cc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md created/updated.\n"
     ]
    }
   ],
   "source": [
    "# STEP 10: write a README snippet (you can edit later)\n",
    "readme_text = \"\"\"# Goa Rental Price Estimator\n",
    "\n",
    "Model saved: models/rf_pipeline.pkl\n",
    "Quick test: use src/models/predict_helper.py to load model and predict.\n",
    "\n",
    "Commands:\n",
    "- To run notebooks: open notebooks/01_preprocessing.ipynb, 02_EDA.ipynb, 03_Modeling.ipynb\n",
    "- To run Streamlit demo later: streamlit run app/app.py\n",
    "\n",
    "\"\"\"\n",
    "Path(\"../README.md\").write_text(readme_text)\n",
    "print(\"README.md created/updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f7c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements.txt written.\n"
     ]
    }
   ],
   "source": [
    "# STEP 11: freeze minimal requirements\n",
    "reqs = [\n",
    "\"pandas\",\n",
    "\"numpy\",\n",
    "\"scikit-learn\",\n",
    "\"xgboost\",\n",
    "\"joblib\",\n",
    "\"shap\",\n",
    "\"matplotlib\",\n",
    "\"seaborn\",\n",
    "\"folium\",\n",
    "\"streamlit\"\n",
    "]\n",
    "Path(\"../requirements.txt\").write_text(\"\\n\".join(reqs))\n",
    "print(\"requirements.txt written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6763fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest... this may take a bit\n",
      "RMSE (log): 0.07213265442604126\n",
      "Saved new pipeline to ../models/rf_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Recreate, retrain and save pipeline in current environment ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) load cleaned data (adjust path if different)\n",
    "df_clean = pd.read_csv(\"../data/processed/goa_cleaned.csv\")\n",
    "\n",
    "# 2) prepare features + target\n",
    "df_model = df_clean.copy()\n",
    "df_model['log_price'] = np.log1p(df_model['price'])\n",
    "\n",
    "X = df_model[['location','sq_feet','bhk_num','price_per_sqft']]\n",
    "y = df_model['log_price']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3) build preprocessor (use sparse_output=False for modern sklearn)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_features = ['sq_feet','bhk_num','price_per_sqft']\n",
    "categorical_features = ['location']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# fit transform quick check\n",
    "_ = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# 4) train RandomForest pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training RandomForest... this may take a bit\")\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# 5) eval quick\n",
    "y_pred = model_rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE (log):\", float(rmse))\n",
    "\n",
    "# 6) save pipeline (overwrite previous file)\n",
    "from joblib import dump\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "dump(model_rf, \"../models/rf_pipeline.pkl\", compress=3)\n",
    "print(\"Saved new pipeline to ../models/rf_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69b8877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest... (may take a little)\n",
      "RMSE (log): 0.07213265442604153\n",
      "Saved new pipeline to ../models/rf_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# RETRAIN & SAVE pipeline (run inside 03_Modeling.ipynb)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import dump\n",
    "\n",
    "# 1) load cleaned data\n",
    "df_clean = pd.read_csv(\"../data/processed/goa_cleaned.csv\")\n",
    "\n",
    "# 2) prepare features + target\n",
    "df_model = df_clean.copy()\n",
    "df_model['log_price'] = np.log1p(df_model['price'])\n",
    "X = df_model[['location','sq_feet','bhk_num','price_per_sqft']]\n",
    "y = df_model['log_price']\n",
    "\n",
    "# 3) split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) preprocessor\n",
    "numeric_features = ['sq_feet','bhk_num','price_per_sqft']\n",
    "categorical_features = ['location']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "_ = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# 5) train RF pipeline\n",
    "model_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training RandomForest... (may take a little)\")\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# 6) eval & save\n",
    "y_pred = model_rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE (log):\", float(rmse))\n",
    "\n",
    "Path(\"../models\").mkdir(parents=True, exist_ok=True)\n",
    "dump(model_rf, \"../models/rf_pipeline.pkl\", compress=3)\n",
    "print(\"Saved new pipeline to ../models/rf_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4972b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (log): 0.07213265442604128\n",
      "✅ Model retrained and overwritten successfully\n"
     ]
    }
   ],
   "source": [
    "# FINAL RETRAIN CELL — run ONLY in 03_Modeling.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load cleaned data\n",
    "df_clean = pd.read_csv(\"../data/processed/goa_cleaned.csv\")\n",
    "\n",
    "# Prepare features\n",
    "df_model = df_clean.copy()\n",
    "df_model[\"log_price\"] = np.log1p(df_model[\"price\"])\n",
    "\n",
    "X = df_model[[\"location\", \"sq_feet\", \"bhk_num\", \"price_per_sqft\"]]\n",
    "y = df_model[\"log_price\"]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", StandardScaler(), [\"sq_feet\", \"bhk_num\", \"price_per_sqft\"]),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"location\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "model_rf = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(\n",
    "            n_estimators=300,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y_test, model_rf.predict(X_test)))\n",
    "print(\"RMSE (log):\", rmse)\n",
    "\n",
    "# SAVE (this overwrites the broken pickle)\n",
    "Path(\"../models\").mkdir(exist_ok=True)\n",
    "dump(model_rf, \"../models/rf_pipeline.pkl\")\n",
    "\n",
    "print(\"✅ Model retrained and overwritten successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
